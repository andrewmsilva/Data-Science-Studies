{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = \"data/IMDB Dataset.csv\"\n",
    "reviews_df = pd.read_csv(csv_file)\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "def preProcess(df, feature, new_column=None):\n",
    "    stop_words = nltk.corpus.stopwords.words()\n",
    "    punctuation = list(string.punctuation)\n",
    "    \n",
    "    tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "    porterStemmer = nltk.PorterStemmer()\n",
    "    snowballStemmer = nltk.SnowballStemmer('english')\n",
    "\n",
    "    pre_processed_data = []\n",
    "    for data in df[feature]:\n",
    "        data = data.replace('<br />', '')\n",
    "        data = data.lower()\n",
    "        \n",
    "        tokens = tokenizer.tokenize(data)\n",
    "        data = ''\n",
    "        for token in tokens:\n",
    "            if token not in stop_words and token not in punctuation:\n",
    "                #token = porterStemmer.stem(token)\n",
    "                token = snowballStemmer.stem(token)\n",
    "                data += token + ' '\n",
    "        \n",
    "        pre_processed_data.append(data)\n",
    "    \n",
    "    if new_column is None:\n",
    "        new_column = feature\n",
    "    df[new_column] = pre_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preProcess(reviews_df, 'review', 'pre-processed-review')\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def getWords(df, feature, target, target_cut=None):\n",
    "    if target_cut is not None:\n",
    "        df = df.query(target + ' == \"' + target_cut + '\"')\n",
    "    \n",
    "    return ' '.join([ word for word in df[feature] ])\n",
    "    \n",
    "def showWordCloud(words):\n",
    "    word_cloud = WordCloud(width=800, height=500, max_font_size=110, collocations=False).generate(words)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.imshow(word_cloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = getWords(reviews_df, 'pre-processed-review', 'sentiment')\n",
    "showWordCloud(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = getWords(reviews_df, 'pre-processed-review', 'sentiment', 'positive')\n",
    "showWordCloud(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = getWords(reviews_df, 'pre-processed-review', 'sentiment', 'negative')\n",
    "showWordCloud(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def getFreqDist(words):\n",
    "    tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "    tokens = tokenizer.tokenize(words)\n",
    "    freq = nltk.FreqDist(tokens)\n",
    "    return pd.DataFrame({'token': list(freq.keys()), 'freq': list(freq.values())})\n",
    "\n",
    "def showPareto(df, n=None):\n",
    "    if n is not None:\n",
    "        df = df.nlargest(columns='freq', n=n)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    ax = sns.barplot(data=df, x='token', y='freq', color='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_freq_df = getFreqDist(all_words)\n",
    "showPareto(all_words_freq_df, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def classify(df, feature, target):\n",
    "    vectorizer = TfidfVectorizer(lowercase=False)\n",
    "    tfidf = vectorizer.fit_transform(df[feature])\n",
    "    \n",
    "    train_data, test_data, train_target, test_target = train_test_split(tfidf, df[target], random_state = 59)\n",
    "    \n",
    "    model = LogisticRegression(solver = 'lbfgs')\n",
    "    model.fit(train_data, train_target)\n",
    "    \n",
    "    return model.score(test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Without pre-processing:\", classify(reviews_df, 'review', 'sentiment'))\n",
    "print(\"Pre-processed:\", classify(reviews_df, 'pre-processed-review', 'sentiment'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
